# Advanced Configuration

## Model Initialization

### Custom Model Loading

You can initialize the model with a specific model file:

```python
from moondream import VL

# Load from a local tar file
model = VL("moondream-latest-mtb.tar")

# Load from a custom path
model = VL("/path/to/custom/model.tar")
```

### Model File Formats

Moondream supports different model file formats:

```python
# Load from .tar format
model = VL("moondream-latest-mtb.tar")

# Load from .bin format
model = VL("moondream-latest-int8.bin")

# Load from .gz format (will be automatically extracted)
model = VL("moondream-latest-int8.bin.gz")
```

## Advanced Features

### Streaming Responses

For longer responses, you can use streaming to get tokens in real-time:

```python
# Streaming captions
for token in model.caption(encoded_image, stream=True)["caption"]:
    print(token, end="", flush=True)

# Streaming question answers
for token in model.query(encoded_image, question, stream=True)["answer"]:
    print(token, end="", flush=True)
```

### Image Processing

Moondream works with PIL Images and provides flexible image handling:

```python
from PIL import Image

# Load and process image
image = Image.open("image.jpg")
encoded_image = model.encode_image(image)

# You can reuse encoded images for multiple queries
caption = model.caption(encoded_image)
answer1 = model.query(encoded_image, "Question 1")
answer2 = model.query(encoded_image, "Question 2")
```

## Best Practices

### Error Handling

Implement comprehensive error handling for robust applications:

```python
try:
    # Model initialization
    model = VL("model_path")
    
    # Image processing
    image = Image.open("image_path")
    encoded_image = model.encode_image(image)
    
    # Generate caption
    caption = model.caption(encoded_image)
    
except FileNotFoundError as e:
    print(f"Model or image file not found: {e}")
except Exception as e:
    print(f"An error occurred: {e}")
```

### Resource Management

Properly manage resources and cleanup:

```python
import os
from PIL import Image

# Temporary file handling
temp_path = "temp_image.jpg"
try:
    image = Image.open("original.jpg")
    image.save(temp_path)
    
    # Process image
    result = model.caption(Image.open(temp_path))
    
finally:
    # Cleanup
    if os.path.exists(temp_path):
        os.remove(temp_path)
```

### Memory Efficiency

For processing multiple images:

```python
# Reuse encoded images when asking multiple questions
encoded_image = model.encode_image(image)

results = []
questions = ["What colors?", "What objects?", "Describe the scene"]

for question in questions:
    answer = model.query(encoded_image, question)
    results.append(answer)
```

## Troubleshooting

Common issues and solutions:

1. **Model Loading Errors**
   ```python
   # Check for model file existence
   if not os.path.exists(model_path):
       print("Please download the model first")
   ```

2. **Memory Issues**
   ```python
   # Process images in batches if needed
   batch_size = 5
   for i in range(0, len(images), batch_size):
       batch = images[i:i+batch_size]
       # Process batch
   ```

3. **Image Format Issues**
   ```python
   # Convert image to RGB if needed
   image = Image.open("image.jpg").convert("RGB")
   ``` 