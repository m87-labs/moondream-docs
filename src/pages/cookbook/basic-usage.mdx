# Basic Usage Examples

Here are some common usage patterns for Moondream.

## Streaming Question Answering

Get real-time responses by streaming tokens:

~~~python
from moondream import VL
from PIL import Image

# Initialize model
model = VL()

# Load image and ask question
image = Image.open("image.jpg")
encoded_image = model.encode_image(image)
question = "Describe this image in detail"

print(f"Q: {question}")
print("A: ", end="", flush=True)

# Stream the response token by token
for token in model.query(encoded_image, question, stream=True)["answer"]:
    print(token, end="", flush=True)
print("\n")
~~~

## A Hardened Image Captioning Example

A robust implementation with proper error handling:

~~~python
import logging
from typing import Optional, Dict
from pathlib import Path
from moondream import VL
from PIL import Image
import torch

class ImageCaptioner:
    def __init__(self, model_path: Optional[str] = None):
        self.logger = logging.getLogger(__name__)
        try:
            self.model = VL(model_path) if model_path else VL()
        except Exception as e:
            self.logger.error(f"Failed to initialize model: {str(e)}")
            raise

    def generate_caption(self, image_path: str) -> Dict[str, str]:
        """
        Generate a caption for the given image with comprehensive error handling.
        
        Args:
            image_path: Path to the image file
            
        Returns:
            Dict containing caption or error message
        """
        try:
            # Validate image path
            if not Path(image_path).exists():
                raise FileNotFoundError(f"Image not found: {image_path}")
                
            # Load and validate image
            try:
                image = Image.open(image_path)
                image.verify()  # Verify image integrity
            except Exception as e:
                raise ValueError(f"Invalid or corrupted image: {str(e)}")
                
            # Generate caption
            encoded_image = self.model.encode_image(image)
            result = self.model.caption(encoded_image)
            
            # Clean up
            del encoded_image
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            return {"status": "success", "caption": result["caption"]}
            
        except FileNotFoundError as e:
            self.logger.error(f"File error: {str(e)}")
            return {"status": "error", "message": str(e)}
            
        except ValueError as e:
            self.logger.error(f"Image error: {str(e)}")
            return {"status": "error", "message": str(e)}
            
        except Exception as e:
            self.logger.error(f"Unexpected error: {str(e)}")
            return {"status": "error", "message": "An unexpected error occurred"}

# Usage example
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    captioner = ImageCaptioner()
    result = captioner.generate_caption("path/to/image.jpg")
    
    if result["status"] == "success":
        print(f"Caption: {result['caption']}")
    else:
        print(f"Error: {result['message']}")
~~~