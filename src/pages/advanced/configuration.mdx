import { Callout } from 'nextra/components'
import { Steps } from 'nextra/components'

# Advanced Configuration

<Callout type="warning">
  Most code examples in this guide demonstrate high-level implementation details and are intended as learning resources and architectural examples. They may need adaptation for your specific use case. The exception is the HuggingFace Transformers implementation, which is taken directly from the official repository and is production-ready.
</Callout>

<Callout type="info">
  Moondream is designed to be accessible and performant across a wide range of hardware. The 2B model runs smoothly on most modern computers, even without a GPU. While this guide offers optimization suggestions, we encourage you to experiment and find what works best for your specific use case.
</Callout>

## Model Selection

Moondream offers different model sizes and configurations to suit various needs. However, don't feel constrained by these suggestions - the models are quite flexible:

- **2B Model**: Our largest model, surprisingly efficient even on CPU-only setups. Great for both development and production.
- **0.5B Model**: A lighter alternative, but the 2B model might still work great for your use case!

<Callout type="info">
  Start with the configuration that seems most straightforward for your needs. You can always optimize later if necessary. Many developers find that the default settings work perfectly fine!
</Callout>

## GPU Setup Guide

<Callout type="info">
  GPU acceleration can significantly improve inference speed, especially for batch processing. However, Moondream is designed to run efficiently on CPU as well, so don't feel pressured to set up GPU support if you don't need it.
</Callout>

### Prerequisites

<Tabs items={['Windows', 'Linux', 'macOS']}>
  <Tabs.Tab>
    - NVIDIA GPU with CUDA support (GTX 10 series or newer recommended)
    - NVIDIA drivers installed and up to date
    - Python 3.8+ (3.10 recommended)
    - Microsoft Visual C++ Redistributable 2019 ([Download here](https://aka.ms/vs/16/release/vc_redist.x64.exe))
    
    To check your GPU and driver:
    1. Right-click desktop → NVIDIA Control Panel
    2. Help → System Information
    3. Look for "NVIDIA Graphics Card" and "Driver Version"
  </Tabs.Tab>
  <Tabs.Tab>
    - NVIDIA GPU with CUDA support (GTX 10 series or newer recommended)
    - NVIDIA drivers installed and up to date
    - Python 3.8+ (3.10 recommended)
    - Build essentials for compilation:
      ```bash
      sudo apt-get update
      sudo apt-get install build-essential
      ```
    
    To check your GPU and driver:
    ```bash
    nvidia-smi
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    - Python 3.8+ (3.10 recommended)
    - Note: GPU acceleration not currently supported on macOS
    - For best performance on Apple Silicon, use the CPU version with a native Python build
  </Tabs.Tab>
</Tabs>

<Steps>
### 1. Install CUDA Toolkit
Download and install CUDA Toolkit 12.1 from NVIDIA's archive:
- [Windows](https://developer.nvidia.com/cuda-12-1-0-download-archive?target_os=Windows)
- [Linux](https://developer.nvidia.com/cuda-12-1-0-download-archive?target_os=Linux)

<Callout type="warning">
  Make sure to select the correct version for your operating system. For Windows users, choose the "Network Installer" for a smoother installation process.
</Callout>

After installation, verify CUDA is properly set up:
```bash
nvcc --version  # Should show CUDA version 12.1
```

### 2. Install PyTorch with CUDA
Install PyTorch with CUDA support using pip:
```bash
pip3 install torch==2.5.1+cu121 torchvision==0.20.1+cu121 --index-url https://download.pytorch.org/whl/cu121
```

<Callout type="info">
  This command installs PyTorch with CUDA 12.1 support. The `+cu121` suffix indicates CUDA 12.1 compatibility.
</Callout>

### 3. Verify GPU Setup
Run this Python script to verify your GPU setup:
```python
import torch

def check_gpu_setup():
    print(f"PyTorch version: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDA version: {torch.version.cuda}")
        print(f"GPU device: {torch.cuda.get_device_name(0)}")
        print(f"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    else:
        print("No CUDA-capable GPU found")

check_gpu_setup()
```

If everything is set up correctly, you should see output similar to:
```
PyTorch version: 2.5.1+cu121
CUDA available: True
CUDA version: 12.1
GPU device: NVIDIA GeForce RTX 3080
GPU memory: 10.24 GB
```
</Steps>

### Troubleshooting Common Issues

1. **CUDA not found**
   - Ensure NVIDIA drivers are up to date
   - Verify CUDA Toolkit installation path is in your system PATH
   - Try restarting your computer

2. **PyTorch CUDA mismatch**
   - Uninstall PyTorch: `pip uninstall torch torchvision`
   - Reinstall with the correct CUDA version as shown above

3. **Out of memory errors**
   - Try using a smaller model variant (e.g., int8 or int4)
   - Reduce batch size if processing multiple images
   - Enable memory optimizations (see below)

<Callout type="info">
  If you're using the Transformers library version of Moondream, check out the [Transformers Guide](./transformers) for specific instructions on enabling GPU acceleration with the HuggingFace implementation.
</Callout>

## Basic Usage

Let's start with the simplest setup - it's often all you need:

```python
from moondream import VL

# This works great on most modern computers!
model = VL("moondream-latest-mtb.tar")
```

## Advanced Model Configurations

While Moondream works well out of the box, here are some additional configuration options you can experiment with. Remember, these are suggestions - feel free to adapt them to your needs!

### HuggingFace Transformers Integration

If you want direct access to model customizations, you can use the transformers library. This is optional but opens up more possibilities for experimentation:

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from PIL import Image

def setup_transformers_model(
    model_id: str = "vikhyatk/moondream2",
    revision: str = "2024-08-26",  # Pin to specific version
    use_cuda: bool = True,
    use_flash_attention: bool = True,
    torch_dtype: torch.dtype = torch.float16,
) -> tuple:
    """Setup Moondream model using transformers with optimizations.
    
    These settings are starting points - feel free to experiment!
    The model performs well even without these optimizations.
    """
    model_kwargs = {
        "trust_remote_code": True,
        "revision": revision,
    }
    
    # Optional CUDA optimizations - the model works great on CPU too!
    if use_cuda and torch.cuda.is_available():
        model_kwargs.update({
            "torch_dtype": torch_dtype,
            "device_map": "auto",
        })
        
        if use_flash_attention:
            model_kwargs["attn_implementation"] = "flash_attention_2"
    
    model = AutoModelForCausalLM.from_pretrained(model_id, **model_kwargs)
    tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)
    
    if use_cuda and torch.cuda.is_available():
        model = model.to("cuda")
    
    return model, tokenizer
```

### Batch Processing

Here's an example of batch processing - useful for handling multiple images, but don't feel pressured to implement this unless you need it:

```python
def process_batch(
    model,
    tokenizer,
    images: list[Image.Image],
    prompts: list[str],
    batch_size: int = 4,  # Experiment with this value!
) -> list[str]:
    """Process multiple images in batches.
    
    The batch_size is just a suggestion - adjust based on your needs.
    Even processing one image at a time works well in many cases!
    """
    all_answers = []
    
    for i in range(0, len(images), batch_size):
        batch_images = images[i:i + batch_size]
        batch_prompts = prompts[i:i + batch_size]
        
        # Optional mixed precision - the model works fine without it too
        with torch.cuda.amp.autocast():
            answers = model.batch_answer(
                images=batch_images,
                prompts=batch_prompts,
                tokenizer=tokenizer,
            )
        all_answers.extend(answers)
    
    return all_answers
```

### Optional Optimizations

Here are some optimization strategies you can explore. Remember, these are optional - the model performs well with default settings on most hardware!

#### GPU Acceleration
```python
# Don't feel pressured to use GPU acceleration
# The model runs great on CPU for many use cases!
model, tokenizer = setup_transformers_model(
    use_cuda=True,
    use_flash_attention=True,
    torch_dtype=torch.float16
)
```

#### Memory Management
```python
# These optimizations are optional
# Start without them and add only if needed
def optimize_memory(model):
    """Optional memory optimizations - use only if needed."""
    if hasattr(model, "gradient_checkpointing_enable"):
        model.gradient_checkpointing_enable()
    
    if hasattr(model, "enable_mem_efficient_attention"):
        model.enable_mem_efficient_attention()
    
    return model
```

#### Multi-GPU Support
```python
# This is for specific high-performance needs
# Most users won't need this configuration
def setup_multi_gpu(
    model_id: str = "vikhyatk/moondream2",
    revision: str = "2024-08-26",
) -> tuple:
    """Optional multi-GPU setup for specific use cases."""
    model = AutoModelForCausalLM.from_pretrained(
        model_id,
        trust_remote_code=True,
        revision=revision,
        device_map="auto",
        torch_dtype=torch.float16,
        attn_implementation="flash_attention_2",
    )
    
    tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)
    
    if torch.cuda.device_count() > 1:
        model = nn.DataParallel(model)
    
    return model, tokenizer
```

### Performance Monitoring

If you're interested in tracking performance metrics, here's an optional monitoring setup:

```python
import nvidia_smi
from dataclasses import dataclass
from typing import Optional

@dataclass
class GPUMetrics:
    memory_used: int
    memory_total: int
    gpu_utilization: int
    power_usage: float
    error: Optional[str] = None

def monitor_gpu_metrics() -> GPUMetrics:
    """Optional GPU monitoring - not required for basic usage."""
    try:
        nvidia_smi.nvmlInit()
        handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)
        info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)
        utilization = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
        power = nvidia_smi.nvmlDeviceGetPowerUsage(handle) / 1000.0
        
        return GPUMetrics(
            memory_used=info.used // 1024**2,
            memory_total=info.total // 1024**2,
            gpu_utilization=utilization.gpu,
            power_usage=power
        )
    except Exception as e:
        return GPUMetrics(0, 0, 0, 0.0, str(e))
    finally:
        nvidia_smi.nvmlShutdown()
```

## Experimentation Guide

We encourage you to experiment with different configurations:

1. **Start Simple**: Begin with the basic setup - it's often all you need!
2. **Measure First**: Before optimizing, check if you actually need it
3. **Gradual Enhancement**: Add optimizations one at a time, testing the impact
4. **Hardware Adaptation**: Adjust configurations based on your specific hardware
5. **Community Learning**: Share your findings with the community - what works best for your use case?

<Callout type="info">
Remember: The configurations in this guide are starting points, not rigid requirements. Moondream is designed to be flexible and performant across different setups. Don't hesitate to experiment and find what works best for you!
</Callout>