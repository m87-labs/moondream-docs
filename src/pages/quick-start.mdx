import Head from 'next/head'
import ConfigSelector from '../components/ConfigSelector';
import FaqDropdown from '../components/FaqDropdown';
import EndpointCard from '../components/EndpointCard';
import { Callout } from 'nextra/components';

<Head>
  <title>Quick Start - Moondream Documentation</title>
  <meta name="description" content="Get up and running with Moondream vision AI in minutes. Step-by-step guide for installation, setup, and basic usage for both local and cloud deployments." />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
  {/* Open Graph */}
  <meta property="og:title" content="Quick Start Guide - Get Started with Moondream Vision AI" />
  <meta property="og:description" content="Get up and running with Moondream vision AI in minutes. Step-by-step guide for installation, setup, and basic usage for both local and cloud deployments." />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://docs.moondream.ai/quick-start" />
  
  
  {/* Twitter */}
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Quick Start Guide - Get Started with Moondream Vision AI" />
  <meta name="twitter:description" content="Get up and running with Moondream vision AI in minutes. Step-by-step guide for installation, setup, and basic usage for both local and cloud deployments." />
  
  
  {/* Schema.org for Google */}
  <script type="application/ld+json">
    {JSON.stringify({
      "@context": "https://schema.org",
      "@type": "HowTo",
      "name": "Getting Started with Moondream Vision AI",
      "description": "Step-by-step guide for installing and setting up Moondream vision AI",
      "step": [
        {
          "@type": "HowToStep",
          "name": "Installation",
          "text": "Install Moondream via pip or npm"
        },
        {
          "@type": "HowToStep",
          "name": "Configuration",
          "text": "Set up your API key and initialize the model"
        },
        {
          "@type": "HowToStep",
          "name": "First Use",
          "text": "Run your first image analysis with Moondream"
        }
      ]
    })}
  </script>
</Head>

<Callout type="warning">
 <Callout type="info" emoji="🚀">
    The latest model release (moondream2-2025-01-09) is currently only available via [Hugging Face](https://huggingface.co/vikhyatk/moondream2) and can be used with the Hugging Face Transformers library. We are actively working on integrating it into our client libraries.
  </Callout>

  ## Installing Pyvips (required for local hf installation)

  For Linux/Mac users, simply run:
  ```bash
  pip install pyvips-binary pyvips
  ```

  For Windows users:
  1. Download 'vips-dev-w64-all-8.16.0.zip' (64-bit) or 'vips-dev-w32-all-8.16.0.zip' (32-bit) from [libvips Windows Releases](https://github.com/libvips/build-win64-mxe/releases)
  2. Extract and copy DLLs from vips-dev-8.16\bin to your project root directory (easier) or System32 (requires admin privileges)
  3. If you choose to add the bin directory to your system PATH, you will need to restart your terminal session

  ## Using Latest Moondream2 via Hugging Face

  The latest version of Moondream2 can be used directly with Hugging Face Transformers:

  ```python
  from transformers import AutoModelForCausalLM, AutoTokenizer
  from PIL import Image

  model = AutoModelForCausalLM.from_pretrained(
      "vikhyatk/moondream2",
      revision="2025-01-09",
      trust_remote_code=True,
      # Uncomment to run on GPU.
      # device_map={"": "cuda"}
  )

  # Captioning
  print("Short caption:")
  print(model.caption(image, length="short")["caption"])

  print("\nNormal caption:")
  for t in model.caption(image, length="normal", stream=True)["caption"]:
      # Streaming generation example, supported for caption() and detect()
      print(t, end="", flush=True)

  # Visual Querying
  print("\nVisual query: 'How many people are in the image?'")
  print(model.query(image, "How many people are in the image?")["answer"])

  # Object Detection
  print("\nObject detection: 'face'")
  objects = model.detect(image, "face")["objects"]
  print(f"Found {len(objects)} face(s)")

  # Pointing
  print("\nPointing: 'person'")
  points = model.point(image, "person")["points"]
  print(f"Found {len(points)} person(s)")
  ```
</Callout>

# Quick Start

<ConfigSelector />

## Explore Our Cloud Endpoints

<div className="grid grid-cols-1 md:grid-cols-2 gap-6 mt-8">
  <EndpointCard
    icon="💬"
    title="/query"
    description="Ask natural language questions about images and receive detailed answers"
    href="/cloud/query"
  />

  <EndpointCard
    icon="📝"
    title="/caption"
    description="Generate accurate and natural image captions"
    href="/cloud/caption"
  />

  <EndpointCard
    icon="🔍"
    title="/detect"
    description="Detect and locate objects in images"
    href="/cloud/detect"
  />

  <EndpointCard
    icon="📍"
    title="/point"
    description="Get precise coordinate locations for objects in images"
    href="/cloud/point"
  />
</div>

## Troubleshooting & FAQ



### Common Questions

<FaqDropdown question='Do I need to encode images before using them with `vl`?'>
  No, the client libraries handle encoding automatically. However, if you plan to make multiple API calls with the same image, encoding it once beforehand will improve performance by avoiding repeated encoding operations.
</FaqDropdown>

<FaqDropdown question='What image formats does Moondream support?'>
  Moondream supports most common image formats like JPEG, PNG, WebP and more. If you want to use a format that is not supported, please let us know on our discord and we can add support.
</FaqDropdown>

<FaqDropdown question="What's the maximum image size supported?">
  There is no strict maximum size limit, but due to the nature of vision-language models, performance tends to deteriorate with very large images. Larger images will still work but may result in reduced accuracy and slower processing times.
</FaqDropdown>

<FaqDropdown question="How do I handle API rate limits? What are the limits for the free tier?">
  The free tier has the following limits:
  - 60 requests per minute
  - 5,000 requests per day

  For higher rate limits and production use cases, please contact us to discuss upgrade options.
</FaqDropdown>

<FaqDropdown question='Why am I getting "Invalid API Key" errors?'>
  Common causes:
  ```txt
  • API key not set correctly in environment variables
  • Using a revoked or expired key
  • Including quotes around the key when setting env vars
  ```
  Make sure to keep your API key secure and never commit it to version control.
</FaqDropdown>

<FaqDropdown question='Can I use Moondream offline?'>
  Yes! Check out our [local installation guide](#installation-options) for running Moondream without API calls. Note that local installations require more computational resources.
</FaqDropdown>
