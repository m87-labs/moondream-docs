import { Tabs } from 'nextra/components'
import { Callout } from 'nextra/components'
import Head from 'next/head'

# /query

<Head>
  <meta name="color-scheme" content="light" />
</Head>

Ask questions about images and get natural language answers.

## Quick Start

First, install the package:

<Tabs items={['Python', 'Node.js']}>
  <Tabs.Tab>
~~~bash
pip install moondream
~~~
  </Tabs.Tab>
  <Tabs.Tab>
~~~bash
npm install moondream
~~~
  </Tabs.Tab>
</Tabs>

Place an image file in your working directory, then:

<Tabs items={['Python', 'Node.js']}>
  <Tabs.Tab>
~~~python
import moondream as md
from PIL import Image

model = md.vl(api_key="your-api-key")

# Load an image (supports PIL.Image, numpy arrays, or file paths)
image = Image.open("./image.jpg")

# Returns str
answer = model.query(image, "What's in this image?")

# Returns Generator[str]
for chunk in model.query(image, "What's in this image?", stream=True):
    print(chunk, end="")
~~~
  </Tabs.Tab>
  <Tabs.Tab>
~~~typescript
import { vl } from "moondream";
import fs from 'fs';

const model = new vl({
  apiKey: "your-api-key" 
});

// Load image (supports Buffer or Base64EncodedImage: { imageUrl: string })
const image = fs.readFileSync('./image.jpg');  // recommended for better performance

// Returns Promise<string>
const answer = await model.query(image, "What's in this image?");

// Returns Promise<{answer: AsyncGenerator<string>}>
const stream = await model.query(image, "What's in this image?", true);
~~~
  </Tabs.Tab>
</Tabs>

## Direct API Access

<Tabs items={['cURL', 'Python', 'Node.js']}>
  <Tabs.Tab>
~~~bash
# Convert image to base64
IMAGE_BASE64=$(base64 -i ./image.jpg)

# Make API request
curl -X POST https://api.moondream.ai/v1/query \
  -H "Content-Type: application/json" \
  -H "X-Moondream-Auth: $MOONDREAM_API_KEY" \
  -d "{
    \"image_url\": \"data:image/jpeg;base64,$IMAGE_BASE64\",
    \"question\": \"What's in this image?\",
    \"stream\": false
  }"
~~~
  </Tabs.Tab>
  <Tabs.Tab>
~~~python
import os
from urllib.request import Request, urlopen
import json
import base64

def get_base64_image(image_path):
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode()

image_base64 = get_base64_image("./image.jpg")
data = {
    "image_url": f"data:image/jpeg;base64,{image_base64}",
    "question": "What's in this image?",
    "stream": False
}

headers = {
    "X-Moondream-Auth": os.getenv("MOONDREAM_API_KEY"),
    "Content-Type": "application/json"
}

req = Request(
    "https://api.moondream.ai/v1/query",
    data=json.dumps(data).encode(),
    headers=headers,
    method="POST"
)

with urlopen(req) as response:
    result = json.loads(response.read())
    print(result["answer"])
~~~
  </Tabs.Tab>
  <Tabs.Tab>
~~~javascript
import fs from 'fs';

async function askQuestion() {
  try {
    const imageBuffer = fs.readFileSync('./image.jpg');
    const imageBase64 = imageBuffer.toString('base64');

    const response = await fetch('https://api.moondream.ai/v1/query', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-Moondream-Auth': process.env.MOONDREAM_API_KEY
      },
      body: JSON.stringify({
        image_url: `data:image/jpeg;base64,${imageBase64}`,
        question: "What's in this image?",
        stream: false
      })
    });

    const data = await response.json();
    console.log(data.answer);
  } catch (error) {
    console.error('Error:', error);
  }
}

askQuestion();
~~~
  </Tabs.Tab>
</Tabs>

<Callout type="info">
  The examples above show both client library usage and direct API access patterns. The client libraries provide the simplest integration, while direct API access offers more control.
</Callout>
