# Moondream Quick Start - Jupyter/Google Colab Demo

Run Moondream in a Jupyter notebook or Google Colab environment with Google Drive integration for easy image analysis.

## Google Colab Setup

> **Note on Google Colab Runtimes:**
> - **CPU (Free Tier)**: Base option, expect 5-10 seconds per response
> - **T4 GPU (Free Tier)**: Switch runtime type to GPU for potential speedup
> - **V100/A100 GPU (Colab Pro)**: Premium GPU options with Colab Pro
> 
> This library is optimized for CPU inference, but you can experiment with GPU runtimes.
> For faster inference, consider:
> 1. Running locally on a decent CPU
> 2. Using GPU runtime in Colab (Runtime > Change runtime type > GPU)
> 3. Upgrading to Colab Pro for better hardware allocation

```python
# Install specific version of moondream
!pip install moondream==0.0.2
print("‚úÖ Moondream installed successfully!")

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')
print("‚úÖ Google Drive mounted successfully!")
```

## Model Options

```python
"""
Available Model Variants:

1. Latest Models (client branch):
   a. Full Precision (FP16)
      - File: moondream-latest-f16.bin.gz
      - Size: 2.88 GB compressed, 3.74 GB uncompressed
      - Best for: Maximum quality and accuracy

   b. 8-bit Quantized (INT8) - Recommended
      - File: moondream-latest-int8.bin.gz
      - Size: 1.83 GB compressed, 2.09 GB uncompressed
      - Best for: Balanced performance and quality

   c. 4-bit Quantized (INT4)
      - File: moondream-latest-int4.bin.gz
      - Size: 1.31 GB compressed, 1.52 GB uncompressed
      - Best for: Resource-constrained environments

2. Lightweight 0.5B Models (onnx branch):
   a. 8-bit Quantized (INT8)
      - File: moondream-0_5b-int8.bin.gz
      - Size: 479 MB compressed, 613 MB uncompressed
      - Best for: Fast inference, limited storage

   b. 4-bit Quantized (INT4)
      - File: moondream-0_5b-int4.bin.gz
      - Size: 375 MB compressed, 479 MB uncompressed
      - Best for: Minimum storage requirements
"""

# Model URLs
MODEL_URLS = {
    # Latest Models
    'int8': "https://huggingface.co/vikhyatk/moondream2/resolve/client/moondream-latest-int8.bin.gz?download=true",
    'fp16': "https://huggingface.co/vikhyatk/moondream2/resolve/client/moondream-latest-f16.bin.gz?download=true",
    'int4': "https://huggingface.co/vikhyatk/moondream2/resolve/client/moondream-latest-int4.bin.gz?download=true",
    # 0.5B Models
    '0.5b-int8': "https://huggingface.co/vikhyatk/moondream2/resolve/onnx/moondream-0_5b-int8.bin.gz?download=true",
    '0.5b-int4': "https://huggingface.co/vikhyatk/moondream2/resolve/onnx/moondream-0_5b-int4.bin.gz?download=true"
}
```

## Download Model Weights

```python
import os
import requests
import gzip
from tqdm import tqdm

def download_model(variant='0.5b-int8', save_dir="/content/drive/MyDrive/moondream"):
    """Download and extract model weights using wget-style direct extraction.
    
    Args:
        variant (str): Model variant to download. Options:
            - 'int8': Latest 2B INT8 model (2.09 GB)
            - 'fp16': Latest 2B FP16 model (3.74 GB)
            - 'int4': Latest 2B INT4 model (1.52 GB)
            - '0.5b-int8': Lightweight INT8 model (613 MB)
            - '0.5b-int4': Lightweight INT4 model (479 MB)
        save_dir (str): Directory to save the model
    """
    if variant not in MODEL_URLS:
        raise ValueError(f"Invalid variant. Choose from: {list(MODEL_URLS.keys())}")
    
    os.makedirs(save_dir, exist_ok=True)
    output_path = os.path.join(save_dir, f"moondream-{variant.replace('0.5b-', '0_5b-')}.bin")
    
    # Check if model already exists
    if os.path.exists(output_path):
        print(f"‚úÖ Model already exists at: {output_path}")
        return output_path
    
    # Download and extract in one step
    print(f"üì• Downloading and extracting {variant} model...")
    print("‚ö†Ô∏è Download time varies by model size and connection speed...")
    response = requests.get(MODEL_URLS[variant], stream=True)
    total_size = int(response.headers.get('content-length', 0))
    
    with open(output_path, 'wb') as f_out:
        with gzip.GzipFile(fileobj=response.raw, mode='rb') as f_gz:
            with tqdm(total=total_size, unit='iB', unit_scale=True) as pbar:
                while True:
                    chunk = f_gz.read(1024*1024)
                    if not chunk:
                        break
                    f_out.write(chunk)
                    pbar.update(len(chunk))
    
    print(f"‚úÖ Model ready at: {output_path}")
    return output_path

# Choose and download model variant
print("\nüì• Downloading lightweight model for basic examples...")
variant = '0.5b-int8'  # Lightweight model for basic usage
model_path = download_model(variant=variant)

# Initialize model with path to weights
print("\nüîÑ Initializing model... (this may take 15-30 seconds)")
model = md.VL(model_path)
print("‚úÖ Model initialized successfully!")
```

## Basic Usage

```python
import moondream as md
from PIL import Image
import requests
from io import BytesIO

print("üîÑ Initializing model... (this may take 15-30 seconds on free tier)...")
# Initialize model with path to weights
model = md.VL(model_path)
print("‚úÖ Model initialized successfully!")

# Use a sample image (cat photo)
SAMPLE_IMAGE_URL = "https://cdn.pixabay.com/photo/2023/01/30/11/04/cat-7755394_1280.jpg"

print("üì• Loading sample image...")
# Load the sample image
response = requests.get(SAMPLE_IMAGE_URL)
image = Image.open(BytesIO(response.content))
print("‚úÖ Image loaded successfully!")

# To use your own image from Google Drive, uncomment the following line:
# image = Image.open("/content/drive/MyDrive/images/your_image.jpg")

print("üîÑ Encoding image... (this may take 5-10 seconds on free tier)...")
# Optional: encode image for multiple queries
encoded_image = model.encode_image(image)
print("‚úÖ Image encoded successfully!")

# Generate caption (with streaming)
print("\nü§ñ Generating caption... (responses will stream in slowly on free tier)...")
for token in model.caption(encoded_image, stream=True)["caption"]:
    print(token, end="", flush=True)
print("\n‚úÖ Caption complete!")

# Ask questions about the image (with streaming)
questions = [
    "What colors are prominent in this image?",
    "What is the main subject?",
    "Describe the lighting conditions.",
    "What is the cat doing in this image?"
]

print("\nü§ñ Starting Q&A... (each response may take 5-10 seconds on free tier)...")
for question in questions:
    print(f"\nQ: {question}")
    print("A: ", end="")
    for token in model.query(encoded_image, question, stream=True)["answer"]:
        print(token, end="", flush=True)
    print("\n‚úÖ Response complete!")
```

## Object Detection

> **‚ö†Ô∏è Coming Soon:** Object detection is an upcoming feature that will be released soon. In the meantime, you can try out object detection and pointing capabilities at [moondream.ai/playground](https://moondream.ai/playground).

Moondream can detect and localize objects or features in images. This example demonstrates detecting cat features (eyes and nose) in our sample image and drawing bounding boxes around them. 

The following code shows how to use the detection feature once it's released:

```python
import moondream as md

# Download the 2B model for detection capabilities
print("\nüì• Downloading 2B model for object detection...")
model_2b_path = download_model('int8')  # 2B INT8 model

# Initialize the 2B model
print("\nüîÑ Initializing 2B model for detection... (this may take 15-30 seconds)")
model_2b = md.VL(model_2b_path)
print("‚úÖ 2B Model initialized successfully!")

from PIL import ImageDraw
from IPython.display import display

def detect_and_visualize(image, model, features=["eyes", "nose"]):
    """Detect and draw bounding boxes for cat features."""
    print("\nüìä Image size:", image.size)
    
    # Create drawing object directly on the image
    draw = ImageDraw.Draw(image)
    
    # Detect each feature
    for feature in features:
        print(f"\nüîç Detecting {feature}...")
        detections = model.detect(image, f"cat {feature}")
        print(f"Found {len(detections)} {feature}:")
        
        # Print detection results
        for i, detection in enumerate(detections, 1):
            print(f"\nDetection {i}:")
            print(f"- Coordinates (normalized):")
            print(f"  x_min: {detection['x_min']:.3f}")
            print(f"  y_min: {detection['y_min']:.3f}")
            print(f"  x_max: {detection['x_max']:.3f}")
            print(f"  y_max: {detection['y_max']:.3f}")
            
            # Convert to pixel coordinates
            x_min = int(detection["x_min"] * image.width)
            y_min = int(detection["y_min"] * image.height)
            x_max = int(detection["x_max"] * image.width)
            y_max = int(detection["y_max"] * image.height)
            
            print(f"- Coordinates (pixels):")
            print(f"  x_min: {x_min}")
            print(f"  y_min: {y_min}")
            print(f"  x_max: {x_max}")
            print(f"  y_max: {y_max}")
            
            # Draw rectangle with different colors for each feature
            color = "red" if feature == "eyes" else "blue"
            
            # Draw rectangle
            print(f"\nDrawing {color} rectangle at [{x_min}, {y_min}, {x_max}, {y_max}]")
            draw.rectangle(
                [x_min, y_min, x_max, y_max],
                outline=color,
                width=3
            )
            
            # Add label with background for better visibility
            text = feature
            text_bbox = draw.textbbox((x_min, y_min - 20), text)
            draw.rectangle(text_bbox, fill=color)
            draw.text(
                (x_min, y_min - 20),
                text,
                fill="white"
            )
    
    # Save a copy to verify drawing worked
    debug_path = "debug_output.jpg"
    image.save(debug_path)
    print(f"\nüíæ Saved debug output to {debug_path}")
    
    # Display the result
    print("\nüñºÔ∏è Displaying result...")
    display(image)
    print("‚úÖ Detection complete!")
    return image

# Run detection on our sample image using the 2B model
print("\nü§ñ Running object detection for cat features...")
result = detect_and_visualize(image, model_2b)

# Verify image was modified
print("\nüîç Verifying image modification:")
print("- Image mode:", result.mode)
print("- Image size:", result.size)
```

## Video Processing (Optional)

Moondream can also process videos frame by frame. This example shows how to detect cat features in a video file, either from Google Drive or a direct URL. Note that video processing can be time-consuming, especially on Colab's free tier.

Here's the video processing code:

```python
import cv2
import numpy as np
from tqdm import tqdm

def process_video(video_path, output_path, model, fps=30):
    """Process a video file with object detection."""
    # Open video
    video = cv2.VideoCapture(video_path)
    
    # Get video properties
    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # Setup output video
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    print(f"\nüé• Processing video with {total_frames} frames...")
    
    # Process each frame
    with tqdm(total=total_frames) as pbar:
        while video.isOpened():
            ret, frame = video.read()
            if not ret:
                break
                
            # Convert BGR to RGB
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(frame_rgb)
            
            # Detect features
            draw_image = pil_image.copy()
            draw = ImageDraw.Draw(draw_image)
            
            for feature in ["eyes", "nose"]:
                detections = model.detect(pil_image, f"cat {feature}")
                color = (255, 0, 0) if feature == "eyes" else (0, 0, 255)  # BGR format
                
                for detection in detections:
                    x_min = int(detection["x_min"] * width)
                    y_min = int(detection["y_min"] * height)
                    x_max = int(detection["x_max"] * width)
                    y_max = int(detection["y_max"] * height)
                    
                    # Convert PIL image back to OpenCV format
                    cv2_image = cv2.cvtColor(np.array(draw_image), cv2.COLOR_RGB2BGR)
                    cv2.rectangle(cv2_image, (x_min, y_min), (x_max, y_max), color, 3)
                    cv2.putText(cv2_image, feature, (x_min, y_min - 10),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
            
            # Write the frame
            out.write(cv2_image)
            pbar.update(1)
    
    # Release everything
    video.release()
    out.release()
    print(f"‚úÖ Video saved to: {output_path}")

# Example usage (commented out):
"""
# Process a video file
video_path = "/content/drive/MyDrive/cat_video.mp4"
output_path = "/content/drive/MyDrive/cat_video_detected.mp4"
process_video(video_path, output_path, model)
"""
```

## Performance Tips for Google Colab

```python
"""
Optimizing Performance on Google Colab:

1. Model Selection:
   - For quick experiments: Use 0.5B models (375-613 MB)
   - For better quality: Use latest models (1.3-3.7 GB)
   - Start with INT8 variants for balanced performance

2. Free Tier CPU:
   - Base performance: 5-10 seconds per response
   - Keep notebook running to avoid reloading model
   - Encode image once for multiple queries

3. GPU Runtime:
   - Available in both free tier (T4) and Colab Pro (V100/A100)
   - Switch runtime: Runtime > Change runtime type > GPU
   - Experiment with different model variants
   - Monitor GPU memory usage

4. Memory Management:
   - Clear memory if needed:
     import gc
     gc.collect()
   - Restart runtime if memory issues persist

5. Best Practices:
   - Run during off-peak hours
   - Keep browser tab active
   - Use small batch sizes
   - Save results frequently
"""
```

## Batch Processing

```python
def process_directory(directory_path, model):
    """Process all images in a directory."""
    results = []
    
    for filename in os.listdir(directory_path):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            image_path = os.path.join(directory_path, filename)
            print(f"\nProcessing: {filename}")
            
            try:
                # Load and encode image
                image = Image.open(image_path)
                encoded_image = model.encode_image(image)
                
                # Generate caption
                caption = model.caption(encoded_image)
                
                results.append({
                    'filename': filename,
                    'caption': caption["caption"]
                })
                
            except Exception as e:
                print(f"Error processing {filename}: {str(e)}")
    
    return results

# Example batch processing
image_dir = "/content/drive/MyDrive/images/batch/"
results = process_directory(image_dir, model)

# Display results
for result in results:
    print(f"\nFile: {result['filename']}")
    print(f"Caption: {result['caption']}")
```

## Save Results

```python
import json
import datetime

def save_results(results, save_dir="/content/drive/MyDrive/moondream/results"):
    """Save analysis results to JSON file."""
    os.makedirs(save_dir, exist_ok=True)
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(save_dir, f"analysis_{timestamp}.json")
    
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"Results saved to: {output_file}")

# Example usage
save_results(results)
```

## Tips and Notes

1. **Model Selection**
   - Use INT8 (recommended) for most cases
   - Use FP16 only if you need maximum accuracy
   - Use INT4 for resource-constrained environments

2. **Performance**
   - This library is optimized for CPU inference
   - For GPU acceleration, consider using the PyTorch implementation
   - Encode images once if you plan to ask multiple questions

3. **Memory Management**
   - Process large batches in chunks
   - Clear variables when not needed:
     ```python
     import gc
     gc.collect()
     ```

4. **Error Handling**
   - Always wrap image processing in try/except blocks
   - Verify file paths and permissions
   - Check image format support

For more examples and advanced usage, see the [Getting Started](/moondream-docs/getting-started) guide.